


import numpy as np
import os
import matplotlib.pyplot as plt
from tqdm import tqdm  
from matplotlib.animation import FuncAnimation
from scipy.integrate import quad

















# Function [x]_{+} 
def positive_part(x):
    """ 
    **Computes the positive part of the input array x.**
    
    Parameters:
    - x (array): Input array n-dimensional.

    Returns:
    - array: Output array with positive parts of array x. 
    """
    return np.maximum(0, x)





def dual_proj_gradient_step(lambda_k, x, B, C, R, G, F, L, u_t):
    """ 
    Performs a projected gradient step on the dual problem using the orthogonal projection method.

    This method solves the dual problem via Orthogonal Gradient Projection over a polytope, applying the projection onto 
    the non-negative orthant (positive part). The gradient of the dual objective function is given by:
    ∇q(λ) = 2CBλ + 2(B^T Rx + Gu(t) + F), and a constant stepsize of 1/L is used, where L is the Lipschitz constant.

    Parameters:
    - lambda_k (array): Current step in the dual problem (dual variables).
    - x (array): Current primal variables or state vector.
    - B (matrix): Matrix involved in the linear transformation of dual variables.
    - C (matrix): Another matrix involved in the linear transformation.
    - R (matrix): Matrix related to the constraints or cost function.
    - G (matrix): Matrix related to the input control term in the gradient expression.
    - F (array): Constant term in the gradient expression.
    - L (float): Lipschitz constant for the gradient step, given by L = 2 * λ_max(CB).
    - u_t (array): Input vector or control function at time t.

    Returns:
    - lambda_{k+1} (array): Next step in the dual projected gradient method, projected onto the non-negative orthant.
    """
    gradient = 2 * (C @ B @ lambda_k + B.T @ (R @ x) + (G * u_t) + F)
    return positive_part(lambda_k - (1 / L) * gradient)




















def solver_dual_problem_eps_eta(x, B, C, R, G, F, P, L, u_t, eps, eta):
    """ 
    Solves the dual problem using the Projected Gradient Method with epsilon-eta approximate projections.

    This method applies the catching-up algorithm with approximate projections to solve a perturbed sweeping process.
    It aims to find an element y ∈ proj_{S(t)}^{ε,η}(x), satisfying two conditions based on ε and η:
    
    1. ||x - y||² ≤ d_{S(t)}(x)² + ε
    2. d_{S(t)}(y) ≤ η

    The solution iterates through the projected gradient steps to ensure that the conditions for ε and η are met.

    Parameters:
    - x (array): Input primal variable or state vector in R^n.
    - B (matrix): Matrix involved in the linear transformation of dual variables.
    - C (matrix): Matrix involved in the gradient calculation.
    - R (matrix): Matrix related to constraints or the cost function.
    - G (matrix): Matrix related to the input control term.
    - F (array): Constant vector involved in the gradient.
    - P (matrix): Matrix used in the calculation of alpha_k for convergence criteria.
    - L (float): Lipschitz constant of the gradient, related to the step size.
    - u_t (array): Input vector or control function at time t.
    - eps (function): Function controlling the precision of the convergence with respect to ε.
    - eta (function): Function controlling the precision of the convergence with respect to η.

    Returns:
    - lambda_k (array): Approximate solution of the dual problem at convergence.
    """
    # Initial iteration for Projected Gradient over the dual problem
    lambda_k = np.array([0.0, 0.0]) # Initial guess \lambda_0 to perform optimization
    lambda_k_plus = dual_proj_gradient_step(lambda_k, x, B, C, R, G, F, L, u_t)
    
    # Compute initial alpha_k for convergence check
    alpha_k = (np.linalg.norm(P) * np.linalg.norm(B @ (lambda_k + lambda_k_plus) + 2 * np.linalg.inv(R) @ x) 
               + 2 * np.linalg.norm(R @ x)) * np.linalg.norm(B)
    
    # Convergence conditions given epsilon and eta
    while (alpha_k * np.linalg.norm(lambda_k - lambda_k_plus) > eps) and \
          (np.linalg.norm(B) * np.linalg.norm(lambda_k - lambda_k_plus) > (eta / np.linalg.norm(R))):

        # Update lambda_{k} = lambda_{k+1}
        lambda_k = lambda_k_plus
        
        # Compute next alpha_k
        alpha_k = (np.linalg.norm(P) * np.linalg.norm(B @ (lambda_k + dual_proj_gradient_step(lambda_k, x, B, C, R, G, F, L, u_t)) + 2 * np.linalg.inv(R) @ x) 
                   + 2 * np.linalg.norm(R @ x)) * np.linalg.norm(B)

        # Compute next step lambda_{k+1}
        lambda_k_plus = dual_proj_gradient_step(lambda_k, x, B, C, R, G, F, L, u_t)
        
    return lambda_k_plus





def approx_proj_eps_eta(x, B, C, R, G, F, P, L, u_t, eps, eta):
    """ 
    Computes an approximate projection of x into S(t) by solving a dual-primal optimization problem 
    using epsilon-eta approximate projections.

    This method solves the dual problem using the Projected Gradient Method and then retrieves the
    approximate solution of the primal problem based on the dual solution.

    Parameters:
    - x (array): Input primal variable or state vector in R^n to be projected into S(t).
    - initial_guess (array): Initial guess for the dual variable (lambda_0) in the Projected Gradient Method.
    - B (matrix): Matrix involved in the linear transformation of dual variables.
    - C (matrix): Matrix involved in the gradient calculation.
    - R (matrix): Matrix related to constraints or the cost function.
    - G (matrix): Matrix related to the input control term.
    - F (array): Constant vector involved in the gradient.
    - P (matrix): Matrix used in the calculation of alpha_k for convergence criteria.
    - L (float): Lipschitz constant of the gradient, related to the step size.
    - u_t (array): Input vector or control function at time t.
    - eps (function): Function controlling the precision of the convergence with respect to ε.
    - eta (function): Function controlling the precision of the convergence with respect to η.

    Returns:
    - y_proj (array): Approximate projection of x into S(t).
    """
    # Compute approximate solution lambda of the dual problem
    lambda_dual = solver_dual_problem_eps_eta(x, B, C, R, G, F, P, L, u_t, eps, eta)
    
    # Compute approximate solution z = B \lambda + R^{-1} x of the primal problem
    z_primal = B @ lambda_dual + np.linalg.inv(R) @ x
    
    # Compute approximate projection of x into S(t)
    y_proj = R @ z_primal
    
    return y_proj








# Define function f(t,x)
def integral_f(t_k, t_k_plus, x, u):
    delta_t = (t_k_plus - t_k) 
    integral_u, _ = quad(u, t_k, t_k_plus)
    return (R @ A @ np.linalg.inv(R)) @ x * delta_t + (R @ E) * integral_u





def solver_Catching_Up_Approx_Proj(x_0, B, C, R, G, F, P, L, u, eps, eta, T, n):
    """
    Applies the Catching-Up Algorithm to compute the trajectory x(t) based on the initial state x_0.
    
    Parameters:
    - x_0 (array): Initial state in R^n. Must be feasible
    - B, C, R, G, F, P (arrays/matrices): Parameters for the dual-primal optimization problem.
    - L (float): Lipschitz constant of the gradient.
    - u (function): Control function.
    - eps (function): Function controlling the precision of the convergence with respect to ε.
    - eta (function): Function controlling the precision of the convergence with respect to η.
    - T: End time of the simulation
    -n: Size of discretization
    Returns:
    - x_solution (list): List of computed state trajectories x(t) over time.
    """
    # Initialize the solution trajectory
    x_solution = [x_0] 
    z_j = R @ x_0  # Convert initial x to z, z = Rx
    # Define the time vector based on T and n
    time = np.linspace(0, T, n)
    
    for j in range(n - 1):
        # Compute z_{j+1} \in approximate projection proj_S(t_{j+1})(z_j + int f(t,z_j)dt)
        z_j_plus = approx_proj_eps_eta(z_j + integral_f(time[j], time[j + 1], z_j, u), B, C, R, G, F, P, L, u(time[j + 1]), eps, eta)
        
        # Compute x_{j+1} = R^{-1}z_{j+1}
        x_j_plus = np.linalg.inv(R) @ z_j_plus
        
        # Save x_{j+1} and update
        x_solution.append(x_j_plus)
        z_j = z_j_plus  # Update z_j for the next iteration

    return np.array(x_solution)





### ------------------------Data settings------------------------###
[R_1, R_2, R_3] = [1,2,1] # Resistor
[L_2, L_3] = [1,2] # Coil
C_4 = 1 # Capacitor

# Time settings
T = 1 # Final time of simulation
n = 100 # Discretization of time

A = np.array([[0.0, 1.0, 0.0],
             [-(1/(L_3*C_4)), -(R_1 + R_3)/L_3, R_1/L_3],
             [0.0, R_1/L_2, -(R_1 + R_2)/L_2]])

B = np.array([[0.0,0.0],
             [1/L_3, 1/L_3],
             [-1/L_2, 0.0]])

C = np.array([[0.0, 1.0, -1.0],
             [0.0, 1.0, 0.0]])

E = np.array([0.0, 1/L_3, 1/L_2])

P = np.array([[1.0, 0.0, 0.0],
             [0.0, L_3, 0],
             [0.0, 0.0, L_2]])

R = np.array([[1, 0.0, 0.0],
             [0.0, np.sqrt(L_3), 0.0],
             [0.0, 0.0, np.sqrt(L_2)]])

F = np.array([0.0, 0.0])

G = np.array([0.0, 0.0])

# For n in N compute epsilon_n, eta_n 
eps = (1/n)**2.1

eta = (1/n)**1.05

# Compute $L$ the Lipschitz constant of the gradient of the objective function given by $L = 2 \lambda_{\max}(CB)$
L = 2*np.max(np.linalg.eigvals(C @ B))

# Test u(t)
def u(t):
    return 16*np.sin(6 * np.pi * t) - 0.5

# Plotting u(t)
t = np.linspace(-1, 1, 400)
u_values = u(t)
plt.figure(figsize=(10, 6))
plt.plot(t, u_values)
plt.title(r'$u(t) = 16sin(6\pi t) - 0.5$')
plt.xlabel('t')
plt.ylabel('u(t)')
plt.grid(True)
plt.show()

# Initial condition, must be feasible.
x_0 = np.array([0.0,0.0,0.0])
x_solution = solver_Catching_Up_Approx_Proj(x_0, B, C, R, G, F, P, L, u, eps, eta, T, n)

# Split into components
time = np.linspace(0, T, n)
x1 = x_solution[:, 0]
x2 = x_solution[:, 1]
x3 = x_solution[:, 2]
# Plots folder
output_folder = 'plots'
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

# Plotting x1 separately
plt.figure(figsize=(12, 8))
plt.plot(time, x1, 'o', label='$x_1$', color='blue', markersize=2)
plt.title('Solution $x_1$ of complementary dynamical system')
plt.xlabel('t')
plt.ylabel('$x_1(t)$')
plt.legend()
plt.grid()

# Save file for x1
output_path_x1 = os.path.join(output_folder, 'solucion_x1.png')
plt.savefig(output_path_x1)
plt.show()

# Plotting x2 and x3 separately
plt.figure(figsize=(12, 8))
plt.plot(time, x2, 'o', label='$x_2$', color='red', markersize=2)
plt.plot(time, x3, 'o', label='$x_3$', color='green', markersize=2)
plt.title('Solution $x = (x_2, x_3)$ of complementary dynamical system')
plt.xlabel('t')
plt.ylabel('x(t)')
plt.legend()
plt.grid()

# Save file for x2 and x3
output_path_x2_x3 = os.path.join(output_folder, 'soluciones_x2_x3.png')
plt.savefig(output_path_x2_x3)
plt.show()





### ------------------------Data settings------------------------###
### Case G not zero and u(t) discontinuos
[R_1, R_2, R_3] = [1,2,1] # Resistor
[L_2, L_3] = [1,2] # Coil
C_4 = 1 # Capacitor

# Time settings
T = 1 # Final time of simulation
n = 120 # Discretization of time

A = np.array([[0.0, 1.0, 0.0],
             [-(1/(L_3*C_4)), -(R_1 + R_3)/L_3, R_1/L_3],
             [0.0, R_1/L_2, -(R_1 + R_2)/L_2]])

B = np.array([[0.0,0.0],
             [1/L_3, 1/L_3],
             [-1/L_2, 0.0]])

C = np.array([[0.0, 1.0, -1.0],
             [0.0, 1.0, 0.0]])

E = np.array([0.0, 1/L_3, 1/L_2])

P = np.array([[1.0, 0.0, 0.0],
             [0.0, L_3, 0],
             [0.0, 0.0, L_2]])

R = np.array([[1, 0.0, 0.0],
             [0.0, np.sqrt(L_3), 0.0],
             [0.0, 0.0, np.sqrt(L_2)]])

F = np.array([0.0, 0.0])

G = np.array([0.0, 0.0])

# For n in N compute epsilon_n, eta_n 
eps = (1/n)**2.1

eta = (1/n)**1.05

# Compute $L$ the Lipschitz constant of the gradient of the objective function given by $L = 2 \lambda_{\max}(CB)$
L = 2*np.max(np.linalg.eigvals(C @ B))

# Test u(t)
#def u(t):
#    return np.sign(np.sin(4 * np.pi * t))

# Plotting u(t)
t = np.linspace(-1, 1, 400)
u_values = u(t)
plt.figure(figsize=(10, 6))
plt.plot(t, u_values)
plt.title(r'$u(t)$')
plt.xlabel('t')
plt.ylabel('u(t)')
plt.grid(True)
plt.show()

# Initial condition, must be feasible.
x_0 = np.array([0.0,0.4,0.0])
x_solution = solver_Catching_Up_Approx_Proj(x_0, B, C, R, G, F, P, L, u, eps, eta, T, n)

# Split into components
time = np.linspace(0, T, n)
x1 = x_solution[:, 0]
x2 = x_solution[:, 1]
x3 = x_solution[:, 2]
# Plots folder
output_folder = 'plots'
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

# Plotting x1 separately
plt.figure(figsize=(12, 8))
plt.plot(time, x1, '-', label='$x_1$', color='blue', markersize=2)
plt.title('Solution $x_1$ of complementary dynamical system')
plt.xlabel('t')
plt.ylabel('$x_1(t)$')
plt.legend()
plt.grid()

# Save file for x1
output_path_x1 = os.path.join(output_folder, 'solucion_x1.png')
plt.savefig(output_path_x1)
plt.show()

# Plotting x2 and x3 separately
plt.figure(figsize=(12, 8))
plt.plot(time, x2, 'o', label='$x_2$', color='red', markersize=2)
plt.plot(time, x3, 'o', label='$x_3$', color='green', markersize=2)
plt.title('Solution $x = (x_2, x_3)$ of complementary dynamical system')
plt.xlabel('t')
plt.ylabel('x(t)')
plt.legend()
plt.grid()

# Save file for x2 and x3
output_path_x2_x3 = os.path.join(output_folder, 'soluciones_x2_x3.png')
plt.savefig(output_path_x2_x3)
plt.show()
print(-C @ x_0 - G * u(0))





# Define el rango de n
n_values = list(range(2, 120, 1))

# Crea la figura y los ejes
fig, ax = plt.subplots(figsize=(10, 6))
# Crea las líneas con colores específicos
colors = ['blue', 'red', 'green']  # Especifica los colores para x1, x2, x3
lines = [ax.plot([], [], '-', label=f'x{i+1}', color=colors[i])[0] for i in range(3)]
ax.set_xlim(0, T)
ax.set_ylim(-1, 1.5)  # Ajusta los límites según lo que necesites
ax.set_title('Solution $x = (x_1, x_2, x_3)$ of complementary dynamical system')
ax.set_xlabel('t')
ax.set_ylabel('x(t)')
ax.legend()
ax.grid()

# Crea un texto vacío para el valor de n
text_n = ax.text(0.5, 0.95, '', transform=ax.transAxes, ha='center', fontsize=14, color='black')

# Función de inicialización
def init():
    for line in lines:
        line.set_data([], [])
    text_n.set_text('')  # Limpia el texto inicial
    return lines + [text_n]

# Función de actualización
def update(frame):
    n = n_values[frame]
    # Cálculo de epsilon y eta
    eps = (1/n)**2.1
    eta = (1/n)**1.05
    # Resolver el problema
    x_solution = solver_Catching_Up_Approx_Proj(x_0, B, C, R, G, F, P, L, u, eps, eta, T, n)
    
    # Actualiza los datos de cada línea
    time = np.linspace(0, T, n)
    for i, line in enumerate(lines):
        line.set_data(time, x_solution[:, i])
    
    # Actualiza el texto con el valor de n
    text_n.set_text(f'Discretización (n): {n}')
    return lines + [text_n]

# Crea la animación con una barra de progreso
with tqdm(total=len(n_values), desc='Procesando', unit='frame') as pbar:
    ani = FuncAnimation(fig, update, frames=len(n_values), init_func=init, blit=False, repeat=False)
    for frame in range(len(n_values)):
        update(frame)
        pbar.update(1)
        
# Guarda la animación
output_path = 'animacion_soluciones.gif'
ani.save(output_path, writer='pillow', fps=10)  # Usamos Pillow para guardar

# Muestra la animación
plt.show()
